{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab 4.1 Data Augmentation with PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader,Subset\n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.util import random_noise\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the `load_data()` function that loads the image using `ImageFolder()` with the specific `transforms.compose()` provided below.\n",
    "`load_data()` will return DataLoader() and print the information about the Dataset.\n",
    "\n",
    "`transforms.Compose()` :\n",
    "- `transforms.Resize()`\n",
    "- `transforms.ToTensor()`\n",
    "- `transforms.Pad()`\n",
    "- `transforms.RandomAffine(degrees=45, translate=(0.1, 0.1),scale=(0.8, 1.2), shear=45)`\n",
    "- `transforms.CenterCrop()`\n",
    "\n",
    "Resource : [`transforms.Compose()`](https://pytorch.org/vision/main/generated/torchvision.transforms.Compose.html#compose), [`torchvision.transforms v1`](<https://pytorch.org/vision/stable/transforms.html#v1-api-reference:~:text=custom)%20tv_tensor%20type.-,V1%20API%20Reference,-Geometry>), [`ImageFolder`](https://pytorch.org/vision/main/generated/torchvision.datasets.ImageFolder.html), [`Dataloader`](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#:~:text=Preparing%20your%20data%20for%20training%20with%20DataLoaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    ### START CODE HERE ###\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Pad(padding=10, fill=0, padding_mode='constant'),\n",
    "        transforms.RandomAffine(degrees=45, translate=(0.1, 0.1), scale=(0.8, 1.2), shear=45),\n",
    "        transforms.CenterCrop((224, 224))\n",
    "    ])\n",
    "\n",
    "    dataset = ImageFolder(path, transform=transform)\n",
    "    \n",
    "    # Print dataset information\n",
    "    print(\"ðŸ“ƒTrain Dataset:\")\n",
    "    class_names = dataset.classes\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        class_count = len([x for x in dataset.targets if x == i])\n",
    "        print(f\"\\tNumber of images in class {class_name}: {class_count}\")\n",
    "    print(f\"\\tNumber of samples: {len(dataset)}\")\n",
    "\n",
    "    data_loader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your load_data() function to load the dataset in the cell below. Then, display the image from the first batch.\n",
    "\n",
    "<details>\n",
    "<summary>\n",
    "<font size=\"3\" color=\"orange\">\n",
    "<b>Expected output</b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "- The output should resemble this, but not be identical\n",
    "\n",
    "```\n",
    "ðŸ“ƒTrain Dataset:\n",
    "\tNumber of images in class battleship: 44\n",
    "\tNumber of images in class patrol boat: 35\n",
    "\tNumber of images in class submarine: 35\n",
    "\tNumber of samples: 114\n",
    "```\n",
    "\n",
    "\n",
    "![image.png](https://github.com/Digital-Image-Processing-Laboratory/Image-Processing-Course-2025/blob/main/Lab4_NN-and-CNN/assets/01.png?raw=true)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Found no valid file for the classes battleship, patrol boat, submarine. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m### START CODE HERE ###\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Load the Ship dataset\u001b[39;00m\n\u001b[32m      3\u001b[39m ship_path = \u001b[33m\"\u001b[39m\u001b[33mShip/Train\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Path to the Ship training dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m data_loader = \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mship_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Get the first batch\u001b[39;00m\n\u001b[32m      7\u001b[39m data_iter = \u001b[38;5;28miter\u001b[39m(data_loader)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mload_data\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_data\u001b[39m(path):\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m### START CODE HERE ###\u001b[39;00m\n\u001b[32m      3\u001b[39m     transform = transforms.Compose([\n\u001b[32m      4\u001b[39m         transforms.Resize((\u001b[32m224\u001b[39m, \u001b[32m224\u001b[39m)),\n\u001b[32m      5\u001b[39m         transforms.ToTensor(),\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m         transforms.CenterCrop((\u001b[32m224\u001b[39m, \u001b[32m224\u001b[39m))\n\u001b[32m      9\u001b[39m     ])\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     dataset = \u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m# Print dataset information\u001b[39;00m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸ“ƒTrain Dataset:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torchvision\\datasets\\folder.py:328\u001b[39m, in \u001b[36mImageFolder.__init__\u001b[39m\u001b[34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    320\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    321\u001b[39m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[32m   (...)\u001b[39m\u001b[32m    326\u001b[39m     allow_empty: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    327\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    337\u001b[39m     \u001b[38;5;28mself\u001b[39m.imgs = \u001b[38;5;28mself\u001b[39m.samples\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torchvision\\datasets\\folder.py:150\u001b[39m, in \u001b[36mDatasetFolder.__init__\u001b[39m\u001b[34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(root, transform=transform, target_transform=target_transform)\n\u001b[32m    149\u001b[39m classes, class_to_idx = \u001b[38;5;28mself\u001b[39m.find_classes(\u001b[38;5;28mself\u001b[39m.root)\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m samples = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmake_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_to_idx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_to_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[38;5;28mself\u001b[39m.loader = loader\n\u001b[32m    159\u001b[39m \u001b[38;5;28mself\u001b[39m.extensions = extensions\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torchvision\\datasets\\folder.py:203\u001b[39m, in \u001b[36mDatasetFolder.make_dataset\u001b[39m\u001b[34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[39m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m class_to_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    199\u001b[39m     \u001b[38;5;66;03m# prevent potential bug since make_dataset() would use the class_to_idx logic of the\u001b[39;00m\n\u001b[32m    200\u001b[39m     \u001b[38;5;66;03m# find_classes() function, instead of using that of the find_classes() method, which\u001b[39;00m\n\u001b[32m    201\u001b[39m     \u001b[38;5;66;03m# is potentially overridden and thus could have a different logic.\u001b[39;00m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThe class_to_idx parameter cannot be None.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmake_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_to_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_empty\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torchvision\\datasets\\folder.py:104\u001b[39m, in \u001b[36mmake_dataset\u001b[39m\u001b[34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[39m\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m extensions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    103\u001b[39m         msg += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSupported extensions are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextensions\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28misinstance\u001b[39m(extensions,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(extensions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(msg)\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m instances\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Found no valid file for the classes battleship, patrol boat, submarine. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "# Load the Ship dataset\n",
    "ship_path = \"Ship/Train\"  # Path to the Ship training dataset\n",
    "data_loader = load_data(ship_path)\n",
    "\n",
    "# Get the first batch\n",
    "data_iter = iter(data_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "# Display images from the first batch\n",
    "fig, axes = plt.subplots(2, 4, figsize=(15, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "class_names = ['battleship', 'patrol boat', 'submarine']\n",
    "\n",
    "for i in range(8):\n",
    "    if i < len(images):\n",
    "        # Convert tensor to numpy and transpose for matplotlib\n",
    "        img = images[i].permute(1, 2, 0).numpy()\n",
    "        # Clip values to [0, 1] range\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f'Class: {class_names[labels[i]]}')\n",
    "        axes[i].axis('off')\n",
    "    else:\n",
    "        axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create your own `CustomImageDataset` that performs the augmentation as in the previous section, but also includes the methods `add_gaussian_blur()` and `add_gaussian_noise()`. **<font color=\"red\">DO NOT</font>** use `transforms.Compose()`.\n",
    "\n",
    "Resource : [CustomImageDataset](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#:~:text=.show()-,Dataset%20class,-torch.utils.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Get all image files and their labels\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.class_names = []\n",
    "        \n",
    "        if root_dir:\n",
    "            for class_idx, class_name in enumerate(sorted(os.listdir(root_dir))):\n",
    "                class_dir = os.path.join(root_dir, class_name)\n",
    "                if os.path.isdir(class_dir):\n",
    "                    self.class_names.append(class_name)\n",
    "                    for img_file in os.listdir(class_dir):\n",
    "                        if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                            self.image_paths.append(os.path.join(class_dir, img_file))\n",
    "                            self.labels.append(class_idx)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Apply manual transformations (without transforms.Compose)\n",
    "        image = self.resize_image(image, (224, 224))\n",
    "        image = self.add_padding(image, padding=10)\n",
    "        image = self.random_affine_transform(image)\n",
    "        image = self.center_crop(image, (224, 224))\n",
    "        \n",
    "        # Apply additional augmentations\n",
    "        if random.random() > 0.5:  # 50% chance\n",
    "            image = self.add_gaussian_blur(image)\n",
    "        if random.random() > 0.5:  # 50% chance\n",
    "            image = self.add_gaussian_noise(image)\n",
    "        \n",
    "        # Convert to tensor\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1)  # HWC to CHW\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def resize_image(self, image, size):\n",
    "        return cv2.resize(image, size)\n",
    "    \n",
    "    def add_padding(self, image, padding):\n",
    "        return cv2.copyMakeBorder(image, padding, padding, padding, padding, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "    \n",
    "    def random_affine_transform(self, image):\n",
    "        h, w = image.shape[:2]\n",
    "        \n",
    "        # Random rotation (Â±45 degrees)\n",
    "        angle = random.uniform(-45, 45)\n",
    "        \n",
    "        # Random translation (Â±10% of image size)\n",
    "        tx = random.uniform(-0.1, 0.1) * w\n",
    "        ty = random.uniform(-0.1, 0.1) * h\n",
    "        \n",
    "        # Random scale (0.8 to 1.2)\n",
    "        scale = random.uniform(0.8, 1.2)\n",
    "        \n",
    "        # Create transformation matrix\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "        M[0, 2] += tx\n",
    "        M[1, 2] += ty\n",
    "        \n",
    "        # Apply transformation\n",
    "        transformed = cv2.warpAffine(image, M, (w, h), borderMode=cv2.BORDER_REFLECT)\n",
    "        return transformed\n",
    "    \n",
    "    def center_crop(self, image, size):\n",
    "        h, w = image.shape[:2]\n",
    "        crop_h, crop_w = size\n",
    "        \n",
    "        start_h = (h - crop_h) // 2\n",
    "        start_w = (w - crop_w) // 2\n",
    "        \n",
    "        return image[start_h:start_h + crop_h, start_w:start_w + crop_w]\n",
    "    \n",
    "    def add_gaussian_blur(self, image):\n",
    "        # Apply Gaussian blur with random kernel size\n",
    "        kernel_size = random.choice([3, 5, 7])\n",
    "        sigma = random.uniform(0.5, 2.0)\n",
    "        return cv2.GaussianBlur(image, (kernel_size, kernel_size), sigma)\n",
    "    \n",
    "    def add_gaussian_noise(self, image):\n",
    "        # Add Gaussian noise using skimage\n",
    "        noise_image = random_noise(image, mode='gaussian', mean=0, var=0.01)\n",
    "        # Convert back to uint8 range\n",
    "        noise_image = (noise_image * 255).astype(np.uint8)\n",
    "        return noise_image\n",
    "    \n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your `CustomImageDataset()` function. Then, display the image from the first batch.\n",
    "\n",
    "<details>\n",
    "<summary>\n",
    "<font size=\"3\" color=\"orange\">\n",
    "<b>Expected output</b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "- The output should resemble this, but not be identical\n",
    "\n",
    "![image-2.png](https://github.com/Digital-Image-Processing-Laboratory/Image-Processing-Course-2025/blob/main/Lab4_NN-and-CNN/assets/02.png?raw=true)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CustomImageDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m### START CODE HERE ###\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Create custom dataset\u001b[39;00m\n\u001b[32m      3\u001b[39m ship_path = \u001b[33m\"\u001b[39m\u001b[33mShip/Train\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m dataset = \u001b[43mCustomImageDataset\u001b[49m(ship_path)\n\u001b[32m      5\u001b[39m dataloader = DataLoader(dataset, batch_size=\u001b[32m16\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers=\u001b[32m0\u001b[39m, pin_memory=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Print dataset information\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'CustomImageDataset' is not defined"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "# Create custom dataset\n",
    "ship_path = \"Ship/Train\"\n",
    "dataset = CustomImageDataset(ship_path)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "# Print dataset information\n",
    "print(\"ðŸ“ƒCustom Dataset:\")\n",
    "print(f\"\\tClasses: {dataset.class_names}\")\n",
    "for i, class_name in enumerate(dataset.class_names):\n",
    "    class_count = sum(1 for label in dataset.labels if label == i)\n",
    "    print(f\"\\tNumber of images in class {class_name}: {class_count}\")\n",
    "print(f\"\\tTotal samples: {len(dataset)}\")\n",
    "\n",
    "# Get first batch and display\n",
    "data_iter = iter(dataloader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "# Display images with custom augmentations\n",
    "fig, axes = plt.subplots(2, 4, figsize=(15, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(8):\n",
    "    if i < len(images):\n",
    "        # Convert tensor to numpy for display\n",
    "        img = images[i].permute(1, 2, 0).numpy()\n",
    "        img = np.clip(img, 0, 1)  # Ensure values are in [0, 1] range\n",
    "        \n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f'Class: {dataset.class_names[labels[i]]}')\n",
    "        axes[i].axis('off')\n",
    "    else:\n",
    "        axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Custom Dataset with Gaussian Blur & Noise Augmentations', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions\n",
    "1. Discuss effects and benefits of fill_mode or padding_mode.\n",
    "2. What would be amount of augmentation should be so that it would not effect the training performance?\n",
    "3. How can we create Salt-and-Pepper Noise, which is the type that greatly affect the image quality?\n",
    "4. What would be transform parameter to simulate camera lense effect?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
